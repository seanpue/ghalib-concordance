{
 "metadata": {
  "name": "",
  "signature": "sha256:3761802d88bcb014441df7364e75c390601ae0889cbd0d2cc466a41a482b6acc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Generates Urdu versions of output\n",
      "\n",
      "This is a bit sloppy right now. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('./graphparser/')\n",
      "import graphparser\n",
      "urdup = graphparser.GraphParser('./graphparser/settings/urdu.yaml')\n",
      "nagarip = graphparser.GraphParser('./graphparser/settings/devanagari.yaml')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<z_consonant> + <z_consonant>\n",
        "<m> + <h_char>\n",
        "<n> + consonant\n",
        "<k> + <kh>\n",
        "<r> + <r>\n",
        "<r> + <z>\n",
        "<l> + <h>\n",
        "<v> + <v>\n",
        "<;t> + <;th>\n",
        "<d> + <d>\n",
        "<consonant> <vowel> <s> + <t> <long_vowel>\n",
        "<consonant> <long_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> <vowel> <vowel_nasal> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> <short_vowel> <h_char> + <consonant>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <long_vowel> <vowel_nasal>\n",
        "<wb> <short_vowel> <consonant> + <consonant> <short_vowel>\n",
        "<wb> <short_vowel> <consonant> + <consonant> <long_vowel> <consonant>\n",
        "<consonant> <short_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<wb> <vowel> <consonant> + <consonant> <vowel>\n",
        "<wb> <consonant> <short_vowel> <z> + <z> <short_vowel> <consonant>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <short_vowel> <consonant>\n",
        "<n> + <consonant>\n",
        "<wb> <long_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> + <consonant>\n",
        "<k> + <k_group>\n",
        "<ch> + <ch_group>\n",
        "<wb> <consonant> <long_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<wb> <consonant> <long_vowel> <consonant> + <consonant> <short_vowel> <consonant>\n",
        "<wb> <consonant> <short_vowel> <sibilant> + <consonant> <wb>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <wb>\n",
        "<wb> <short_vowel> <consonant> + <consonant> <long_vowel> <wb>\n",
        "<wb> <short_vowel> <consonant> + <consonant> <long_vowel> <consonant> <wb>\n",
        "<wb> <short_vowel> <consonant> <short_vowel> <consonant> + <consonant> <short_vowel> <consonant>\n",
        "<vowel> <n> + <consonant>\n",
        "<consonant> + <n> <aa> <wb>\n",
        "<consonant> + <n> <e> <wb>\n",
        "<consonant> + <t> <aa> <wb>\n",
        "<consonant> + <t> <e> <wb>\n",
        "<consonant> + <t> <ii> <wb>\n",
        "<consonant> + <ain> <short_vowel> <wb>\n",
        "<short_vowel> <ain> + <consonant>\n",
        "<wb> <consonant> <short_vowel> + <consonant> <long_vowel>\n",
        "<wb> <consonant> <short_vowel> <consonant> + <consonant> <long_vowel>\n",
        "<consonant> + <consonant>\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print urdup.parse('shaan-e shaan').output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u0634\u0627\u0646\u0650 \u0634\u0627\u0646\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "def unicode_csv_reader(unicode_csv_data, **kwargs):\n",
      "    # csv.py doesn't do Unicode; encode temporarily as UTF-8:\n",
      "    csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),\n",
      "                             **kwargs)\n",
      "    for row in csv_reader:\n",
      "        # decode UTF-8 back to Unicode, cell by cell:\n",
      "        yield [unicode(cell, 'utf-8') for cell in row]\n",
      "\n",
      "def utf_8_encoder(unicode_csv_data):\n",
      "    for line in unicode_csv_data:\n",
      "        yield line.encode('utf-8')\n",
      "import csv, codecs, cStringIO\n",
      "\n",
      "class UTF8Recoder:\n",
      "    \"\"\"\n",
      "    Iterator that reads an encoded stream and reencodes the input to UTF-8\n",
      "    \"\"\"\n",
      "    def __init__(self, f, encoding):\n",
      "        self.reader = codecs.getreader(encoding)(f)\n",
      "\n",
      "    def __iter__(self):\n",
      "        return self\n",
      "\n",
      "    def next(self):\n",
      "        return self.reader.next().encode(\"utf-8\")\n",
      "\n",
      "class UnicodeReader:\n",
      "    \"\"\"\n",
      "    A CSV reader which will iterate over lines in the CSV file \"f\",\n",
      "    which is encoded in the given encoding.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, f, dialect=csv.excel, encoding=\"utf-8\", **kwds):\n",
      "        f = UTF8Recoder(f, encoding)\n",
      "        self.reader = csv.reader(f, dialect=dialect, **kwds)\n",
      "\n",
      "    def next(self):\n",
      "        row = self.reader.next()\n",
      "        return [unicode(s, \"utf-8\") for s in row]\n",
      "\n",
      "    def __iter__(self):\n",
      "        return self\n",
      "\n",
      "class UnicodeWriter:\n",
      "    \"\"\"\n",
      "    A CSV writer which will write rows to CSV file \"f\",\n",
      "    which is encoded in the given encoding.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, f, dialect=csv.excel, encoding=\"utf-8\", **kwds):\n",
      "        # Redirect output to a queue\n",
      "        self.queue = cStringIO.StringIO()\n",
      "        self.writer = csv.writer(self.queue, dialect=dialect, **kwds )\n",
      "        self.stream = f\n",
      "        self.encoder = codecs.getincrementalencoder(encoding)()\n",
      "\n",
      "    def writerow(self, row):\n",
      "        self.writer.writerow([s.encode(\"utf-8\") for s in row])\n",
      "        # Fetch UTF-8 output from the queue ...\n",
      "        data = self.queue.getvalue()\n",
      "        data = data.decode(\"utf-8\")\n",
      "        # ... and reencode it into the target encoding\n",
      "        data = self.encoder.encode(data)\n",
      "        # write to the target stream\n",
      "        self.stream.write(data)\n",
      "        # empty queue\n",
      "        self.queue.truncate(0)\n",
      "\n",
      "    def writerows(self, rows):\n",
      "        for row in rows:\n",
      "            self.writerow(row)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_urdu_statistics(inputfile,outputfile,nagari=False,headers=True):\n",
      "    with open(outputfile,'w') as output_stream:\n",
      "        csvwriter = UnicodeWriter(output_stream)\n",
      "        if headers==True:\n",
      "            fieldnames = ['urdu', 'transliteration','count']\n",
      "            if nagari==True:\n",
      "                fieldnames=['urdu', 'nagari', 'transliteration','count']\n",
      "            csvwriter.writerow(fieldnames) # add headers\n",
      "            \n",
      "        with open(inputfile,'r') as input_stream:\n",
      "            csvreader = unicode_csv_reader(input_stream) # this is likely not utf-8\n",
      "            for row in csvreader:\n",
      "                (token,freq)=row\n",
      "                if nagari==True:\n",
      "                    row = urdup.parse(token).output,nagarip.parse(token).output,token,freq\n",
      "                else:\n",
      "                    row = urdup.parse(token).output, token, freq\n",
      "                csvwriter.writerow(row)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_all_urdu_statistics():\n",
      "    write_urdu_statistics('output/statistics/izafat-freq.csv','output/statistics/izafat-freq-ur.csv') # will contain transliteration for now\n",
      "    write_urdu_statistics('output/statistics/lemmas-beta-freq.csv','output/statistics/lemmas-beta-freq-ur.csv')\n",
      "    write_urdu_statistics('output/statistics/uniquetokens-freq.csv','output/statistics/uniquetokens-freq-ur.csv')\n",
      "    write_urdu_statistics('output/statistics/izafatastokens-freq.csv','output/statistics/izafatastokens-freq-ur.csv')\n",
      "    write_urdu_statistics('output/statistics/izafatastokens-freq.csv','output/statistics/izafatastokens-freq-hiur.csv',nagari=True)\n",
      "    write_urdu_statistics('output/statistics/lemma-counts.csv', 'output/statistics/lemma-counts-ur.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_all_urdu_statistics()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- this is a\n",
      "  - nested list?\n",
      "    - is it not?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}