{
 "metadata": {
  "name": "",
  "signature": "sha256:a66d8fdaf54f814756b5cc6c4a68563047c91f72636392d1032f47fc5126c7e1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Generates Urdu versions of output\n",
      "\n",
      "This is a bit sloppy right now. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('./graphparser/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import graphparser"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "urdup = graphparser.GraphParser('./graphparser/settings/urdu.yaml')\n",
      "nagarip = graphparser.GraphParser('./graphparser/settings/devanagari.yaml')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print urdup.parse('shaan-e shaan').output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u0634\u0627\u0646\u0650 \u0634\u0627\u0646\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "def unicode_csv_reader(unicode_csv_data, **kwargs):\n",
      "    # csv.py doesn't do Unicode; encode temporarily as UTF-8:\n",
      "    csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),\n",
      "                             **kwargs)\n",
      "    for row in csv_reader:\n",
      "        # decode UTF-8 back to Unicode, cell by cell:\n",
      "        yield [unicode(cell, 'utf-8') for cell in row]\n",
      "\n",
      "def utf_8_encoder(unicode_csv_data):\n",
      "    for line in unicode_csv_data:\n",
      "        yield line.encode('utf-8')\n",
      "import csv, codecs, cStringIO\n",
      "\n",
      "class UTF8Recoder:\n",
      "    \"\"\"\n",
      "    Iterator that reads an encoded stream and reencodes the input to UTF-8\n",
      "    \"\"\"\n",
      "    def __init__(self, f, encoding):\n",
      "        self.reader = codecs.getreader(encoding)(f)\n",
      "\n",
      "    def __iter__(self):\n",
      "        return self\n",
      "\n",
      "    def next(self):\n",
      "        return self.reader.next().encode(\"utf-8\")\n",
      "\n",
      "class UnicodeReader:\n",
      "    \"\"\"\n",
      "    A CSV reader which will iterate over lines in the CSV file \"f\",\n",
      "    which is encoded in the given encoding.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, f, dialect=csv.excel, encoding=\"utf-8\", **kwds):\n",
      "        f = UTF8Recoder(f, encoding)\n",
      "        self.reader = csv.reader(f, dialect=dialect, **kwds)\n",
      "\n",
      "    def next(self):\n",
      "        row = self.reader.next()\n",
      "        return [unicode(s, \"utf-8\") for s in row]\n",
      "\n",
      "    def __iter__(self):\n",
      "        return self\n",
      "\n",
      "class UnicodeWriter:\n",
      "    \"\"\"\n",
      "    A CSV writer which will write rows to CSV file \"f\",\n",
      "    which is encoded in the given encoding.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, f, dialect=csv.excel, encoding=\"utf-8\", **kwds):\n",
      "        # Redirect output to a queue\n",
      "        self.queue = cStringIO.StringIO()\n",
      "        self.writer = csv.writer(self.queue, dialect=dialect, **kwds )\n",
      "        self.stream = f\n",
      "        self.encoder = codecs.getincrementalencoder(encoding)()\n",
      "\n",
      "    def writerow(self, row):\n",
      "        self.writer.writerow([s.encode(\"utf-8\") for s in row])\n",
      "        # Fetch UTF-8 output from the queue ...\n",
      "        data = self.queue.getvalue()\n",
      "        data = data.decode(\"utf-8\")\n",
      "        # ... and reencode it into the target encoding\n",
      "        data = self.encoder.encode(data)\n",
      "        # write to the target stream\n",
      "        self.stream.write(data)\n",
      "        # empty queue\n",
      "        self.queue.truncate(0)\n",
      "\n",
      "    def writerows(self, rows):\n",
      "        for row in rows:\n",
      "            self.writerow(row)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_urdu_statistics(inputfile,outputfile,nagari=False,headers=True):\n",
      "    with open(outputfile,'w') as output_stream:\n",
      "        csvwriter = UnicodeWriter(output_stream)\n",
      "        if headers==True:\n",
      "            fieldnames = ['urdu', 'transliteration','count']\n",
      "            if nagari==True:\n",
      "                fieldnames=['urdu', 'nagari', 'transliteration','count']\n",
      "            csvwriter.writerrow(fieldnames) # add headers\n",
      "            \n",
      "        with open(inputfile,'r') as input_stream:\n",
      "            csvreader = unicode_csv_reader(input_stream) # this is likely not utf-8\n",
      "            for row in csvreader:\n",
      "                (token,freq)=row\n",
      "                if nagari==True:\n",
      "                    row = urdup.parse(token).output,nagarip.parse(token).output,token,freq\n",
      "                else:\n",
      "                    row = urdup.parse(token).output, token, freq\n",
      "                csvwriter.writerow(row)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def write_all_urdu_statistics():\n",
      "    write_urdu_statistics('output/statistics/izafat-freq.csv','output/statistics/izafat-freq-ur.csv') # will contain transliteration for now\n",
      "    write_urdu_statistics('output/statistics/lemmas-beta-freq.csv','output/statistics/lemmas-beta-freq-ur.csv')\n",
      "    write_urdu_statistics('output/statistics/uniquetokens-freq.csv','output/statistics/uniquetokens-freq-ur.csv')\n",
      "    write_urdu_statistics('output/statistics/izafatastokens-freq.csv','output/statistics/izafatastokens-freq-ur.csv')\n",
      "    write_urdu_statistics('output/statistics/izafatastokens-freq.csv','output/statistics/izafatastokens-freq-hiur.csv',nagari=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "write_all_urdu_statistics()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "'fieldnames' is an invalid keyword argument for this function",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-36-350aa9f48c99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_all_urdu_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-35-83f299ebaa89>\u001b[0m in \u001b[0;36mwrite_all_urdu_statistics\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrite_all_urdu_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mwrite_urdu_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/statistics/izafat-freq.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'output/statistics/izafat-freq-ur.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# will contain transliteration for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mwrite_urdu_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/statistics/lemmas-beta-freq.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'output/statistics/lemmas-beta-freq-ur.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwrite_urdu_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/statistics/uniquetokens-freq.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'output/statistics/uniquetokens-freq-ur.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mwrite_urdu_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/statistics/izafatastokens-freq.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'output/statistics/izafatastokens-freq-ur.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-34-6173273f18eb>\u001b[0m in \u001b[0;36mwrite_urdu_statistics\u001b[0;34m(inputfile, outputfile, nagari)\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mfieldnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'urdu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nagari'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'transliteration'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mcsvwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnicodeWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfieldnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mcsvwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# add headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-33-0f5a906e8f5a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, dialect, encoding, **kwds)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Redirect output to a queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcStringIO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetincrementalencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mTypeError\u001b[0m: 'fieldnames' is an invalid keyword argument for this function"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}